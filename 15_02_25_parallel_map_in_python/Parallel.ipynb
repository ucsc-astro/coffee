{
 "metadata": {
  "name": "",
  "signature": "sha256:27416fa0e521e5264aaa18519c480db4902d6e79b10ea016ed1bd49afee1ddad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "from scipy.integrate import odeint\n",
      "import multiprocessing\n",
      "import sys\n",
      "import functools\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Embarrassingly Parallel Programming in Python\n",
      "==================\n",
      "\n",
      "### What is parallel programming?\n",
      "Most computers these days can do multiple things at once, using multiple *cores*.  This is great, as it allows your computer to do multiple things simultaneously, without tying up your computer.\n",
      "\n",
      "But sometimes, those extra cores in our computer are going to waste.  You're waiting for your stellar model to converge, and it's taking forever, but only 1 of 4 cores is actually doing any work.\n",
      "\n",
      "It'd be great to get some of those other cores to help out when it's needed. That won't be all the time, but for slow running code, there are ways you can easily cut runtime by half, with only minor modifications\n",
      "\n",
      "### What is \"Embarrassingly Parallel\" Programming?\n",
      "Basically, when you have lots of **independent** processes.  This is the simplest version of parallel programming, **but it also offers the most speedup**.\n",
      "\n",
      "**Good example**: Given the astrometry of a nearby star, I want to integrate its motion backwards 10<sup>4</sup> times, slightly varying its initial conditions each time. This will let me estimate how the uncertainty in its current position effects the uncertainty of how close it passed by the Sun.\n",
      "\n",
      "**Bad example**: Given a comoving box, filled with N<sub>bodies</sub>, where N<sub>bodies</sub>=10<sup>9</sup>, and cosmological initial conditions, what would you expect the local cosmic web to look like at z=0.\n",
      "\n",
      "The **good** example is good because it's independent.  You know the 10<sup>4</sup> initial conditions you want to test.  The **bad** example is bad because it's so dependent.  Each body depends on the location of every other body, and each time step depends on the previous timestep.\n",
      "\n",
      "There are times when you'll need something more complicated, rather than \"embarassingly easy,\" but even those tasks will often have steps that are \"embarrasingly parallel,\" so this is a good place to start.\n",
      "\n",
      "\n",
      "\n",
      "### This talk is meant to:\n",
      "- introduce to parallel programming:\n",
      "- show when it can make your research go faster\n",
      "- show that it can be easy in python\n",
      "\n",
      "\n",
      "### This talk **isn't** meant to:\n",
      "- be an indepth discussion of the inner workings\n",
      "- be a guide on parallel computing on distributed clusters\n",
      "\n",
      "Those topics are interesting, and could be important for your work, but I'm going to keep it simple for today.  At the end I'll add some other readings I've found helpful.\n",
      "\n",
      "Also, it should be noted that Python is an interpretted language, and behaves quite different than Fortan, C/C++, etc. Python has its own set of challenges, and the tools you use in compiled languages might not apply in Python."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basic Concepts\n",
      "----------\n",
      "\n",
      "Before we jump into multiprocessing, it'll be good to start with a bit of background.\n",
      "\n",
      "The simplest time to incorporate paralle programming is within the *map - filter - reduce* model. It's neither perfect nor comprehensive, but it's a starting point.\n",
      "\n",
      "**Mapping** is when you start with a set of inputs, apply a function to them to return a different set of outputs. In linear algebra, a matrix is something that maps an input vector to an output vector. (E.g. a rotation matrix can rotate [map] a vector along $\\hat{x}$ to a vector along $\\hat{y}$).  For scalars, a function is what maps a scalar to a scalar. (E.g. cosmology calculators can map values of redshift, $z$ to luminosity distance, $D_L$.)\n",
      "\n",
      "In Python a **map** is a function which can be applied to a large number of inputs **element-wise**. In this way it's not too different from a simple for loop, or a list comprehension.\n",
      "\n",
      "A Python **filter** is then a function that allows you to filter out unwanted values.  Maybe you want to remove observing data when there was bad data. Maybe you want to remove data for a certain type of object.  A **filter** will take a list, and only return the values which pass your filtering function. \n",
      "\n",
      "Finally, a **reduce** function allows you to combine all your data into a single number, rather than a list of elements.  Maybe now that have a collection of good pixels, you want the total photometric flux and uncertainty. Maybe you want to integrate some value over your IMF.\n",
      "**NOTE: <code>reduce</code> has been removed by Python 3. ** If you really need it, check out: https://docs.python.org/3.0/library/functools.html#functools.reduce\n",
      "\n",
      "The archetypal program flow is this: you have some initial inputs listing what you want to process.  **Map** does the work for each of those elements. **Filter** lets you mask / remove unwanted results.  **Reduce** helps you combine it into a reduced value.  As always, the process is much more fluid in reality."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Map - Filter - Reduce Example\n",
      "Given a temperatures in Celcius, convert it to Fahrenheit, and get the average of all the readings below freezing.\n",
      "\n",
      "**NOTE:** the serialized Map-Reduce framework behaves differently between Python2 and Python3. (E.g. <code>reduce</code> has been eliminated, <code>map</code> now uses \"lazy\" evaluation, etc.)  There are probably better ways to do this in Python3; these work-arounds aren't ideal.  But our focus is on parallel code, so this won't affect us much."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getF(C):\n",
      "    return C*9./5 + 32\n",
      "\n",
      "def isFreezingF(F):\n",
      "    if F < 32:\n",
      "        return True\n",
      "    else:\n",
      "        return False # return 0 or False to be filtered out\n",
      "\n",
      "\n",
      "Cs = [-9.2, 6.5, -17.3, 37.8]\n",
      "\n",
      "Fs = list(map(getF, Cs))\n",
      "\n",
      "Freezing = list(filter(isFreezingF, Fs))\n",
      "num_freezing = len(list(Freezing))\n",
      "if sys.version_info[0] is 3:\n",
      "    # Python 3\n",
      "    Fs = list(map(getF, Cs)) #force non-lazy evaluation\n",
      "    Freezing = list(filter(isFreezingF, Fs)) #force non-lazy evaluation\n",
      "    num_freezing = len(Freezing)\n",
      "    FreezingAverage = functools.reduce(np.add, Freezing) / num_freezing\n",
      "else:\n",
      "    # Python != 3\n",
      "    Fs = map(getF, Cs)\n",
      "    Freezing = filter(isFreezingF, Fs)\n",
      "    num_freezing = len(Freezing)\n",
      "    FreezingAverage = functools.reduce(np.add, Freezing) / num_freezing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "print(\"Temperatures in C: \", Cs)\n",
      "print(\"Temperatures in F: \", Fs)\n",
      "print(\"Temperatures which are below freezing: \", Freezing)\n",
      "print(\"Average Temperature when it is freezing: \", FreezingAverage, \"F\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Temperatures in C:  [-9.2, 6.5, -17.3, 37.8]\n",
        "Temperatures in F:  [15.440000000000001, 43.7, 0.8599999999999959, 100.03999999999999]\n",
        "Temperatures which are below freezing:  [15.440000000000001, 0.8599999999999959]\n",
        "Average Temperature when it is freezing:  8.15 F\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Let's try a \"real\" problem.\n",
      "\n",
      "Given a potential:\n",
      "    $$ \\Phi = \\ln r + V(\\phi) = \\ln r + \\ln (1 - e \\cos \\phi) $$\n",
      "with an eccentricity $ e = .3 $, and a dimensionless energy $ E = -1 $, try integrating a number of test particles for a range of initial radii $ x_0 < x_\\mathrm{max} = \\frac{\\exp^{E}}{1 - e} \\approx 0.52$.\n",
      "\n",
      "I.e. integrate particles in the given potential with the initial conditions:\n",
      "$$ x_0 \\in (0, x_\\mathrm{max})$$\n",
      "$$ y_0 = 0 $$\n",
      "$$ \\dot{x}_0 = 0 $$\n",
      "$$ \\dot{y}_0 = \\sqrt{2 ( E - \\Phi) - \\dot{x_0}^2} $$\n",
      "\n",
      "This sounds like an excellent time to use this *map* framework.  We have a range of initial conditions, which have to get processed by the same potential with the same physics, and each integration is independent of all the rest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eccentricity = .3\n",
      "Energy       = -1\n",
      "x_max        = np.exp(Energy) / (1 - eccentricity)\n",
      "\n",
      "#padding to be added to avoid scientifically interesting,\n",
      "#  but numerically problematic initial conditions\n",
      "padding      = .1\n",
      "x_0s         = np.linspace(padding, x_max - padding) \n",
      "\n",
      "\n",
      "def derivs(w, t, eccentricity):\n",
      "    x,y, v_x, v_y = w\n",
      "    \n",
      "    r = np.sqrt(x**2 + y**2)\n",
      "    denominator = r**2 - (eccentricity * x * r)\n",
      "\n",
      "    # Calculate accelerations    \n",
      "    a_x = -1*(x - eccentricity * r) / denominator\n",
      "    a_y = -1*y / denominator\n",
      "    \n",
      "    return [v_x, v_y, a_x, a_y]\n",
      "\n",
      "def integrate(x_0, eccentricity=eccentricity, hmax=.1, num_steps=100):\n",
      "    x_0 = x_0\n",
      "    y_0 = 0\n",
      "    v_x_0 = 0\n",
      "    v_y_0 = np.sqrt(2 *(Energy - (np.log(x_0 * (1-eccentricity)))))\n",
      "    \n",
      "    w_0 = [x_0, y_0, v_x_0, v_y_0]\n",
      "    \n",
      "    ts = np.linspace(0,100, num=num_steps)\n",
      "    ws = odeint(derivs, w_0, ts, args = (eccentricity,), hmax=hmax)\n",
      "    ## if this was real work, you'd want to save your results now\n",
      "    ##   or return ws, or do something before you lose your results\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Running these integrations -- For loop vs. Map\n",
      "How do the methods compare?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Serial example\n",
      "\n",
      "for x_0 in x_0s:\n",
      "    integrate(x_0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 11 s, sys: 38.5 ms, total: 11 s\n",
        "Wall time: 11 s\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Serial example\n",
      "\n",
      "if sys.version_info[0] is 3:\n",
      "    # Python 3\n",
      "    result = list(map(integrate, x_0s)) # Force non-lazy evaluation\n",
      "else:\n",
      "    # Python != 3\n",
      "    result = map(integrate, x_0s)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 11.1 s, sys: 33.4 ms, total: 11.1 s\n",
        "Wall time: 11.2 s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A little better, but not by much...\n",
      "(Map becomes more useful for large datasets, which return a large set of results)\n",
      "\n",
      "### Let's try in parallel\n",
      "First, check how many cores are available"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(multiprocessing.cpu_count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now use the <code>multiprocessing.Pool</code> version of <code>map</code>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = multiprocessing.Pool(2) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 10.4 ms, sys: 7.85 ms, total: 18.2 ms\n",
        "Wall time: 6.03 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = multiprocessing.Pool(4) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 11 ms, sys: 11.5 ms, total: 22.5 ms\n",
        "Wall time: 5.13 s\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = multiprocessing.Pool(8) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 17.8 ms, sys: 19.6 ms, total: 37.4 ms\n",
        "Wall time: 5.26 s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "pool = multiprocessing.Pool(32) # initialize thread pool N threads\n",
      "pool.map(integrate, x_0s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 41.8 ms, sys: 64 ms, total: 106 ms\n",
        "Wall time: 5.09 s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### What does this show?\n",
      "First, we had to make very few changes to our code. It can be easy to improve existing projects.\n",
      "\n",
      "Also, we see that <code>pool.map</code> is much faster than the normal <code>map</code>, and that as we use more threads, things speed up.  But there's a limit. If our computer only has 4 cores available, creating more than 4 threads isn't very useful. In some cases it can actually *add* administrative overhead, while not adding any computing power."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Beyond simple maps\n",
      "Using <code>pool.map</code> *requires* that you use *exactly* the same function on each input, without any keywords.  Often times we want a bit more flexibility.\n",
      "\n",
      "<code>apply_async</code> allows us to explicitly pass arbitrary inputs to arbitrary functions.  This can be cumbersome, but what you lose in elegance, you gain in flexibility.\n",
      "\n",
      "### Let's try an example where we change the potential, while keeping the initial condition fixed:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Serial example\n",
      "\n",
      "eccentricities = [.3, .4, .5, .6]\n",
      "result_list = []\n",
      "\n",
      "for e in eccentricities:\n",
      "    # Will start an integration, and wait for it to finish before moving on to the next one.\n",
      "    result = integrate(.2, eccentricity=e, hmax = .0005, num_steps = 100000)\n",
      "    result_list.append(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 9 s, sys: 79.6 ms, total: 9.08 s\n",
        "Wall time: 9.04 s\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "## Parallel example\n",
      "\n",
      "eccentricities = [.3, .4, .5, .6]\n",
      "result_list = []\n",
      "integration_list = []\n",
      "\n",
      "pool = multiprocessing.Pool(4)\n",
      "\n",
      "for e in eccentricities:\n",
      "    # will start an integration, but continue through the for loop, *without waiting for integrations to finish*\n",
      "    integration = pool.apply_async(integrate, [.2], {\"eccentricity\" : e, \"hmax\" : .0005, \"num_steps\":100000} )\n",
      "    integration_list.append(integration)\n",
      "\n",
      "for integration in integration_list:\n",
      "    # .get() forces python to wait until the process completes\n",
      "    #   Otherwise Python will continue going through your file, without waiting for your results\n",
      "    #   If done incorrectly, this can cause a \"race condition\" where you incorrectly assume the process is complete\n",
      "    result = integration.get()\n",
      "    result_list.append(result)\n",
      "    \n",
      "pool.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 15.7 ms, sys: 14 ms, total: 29.7 ms\n",
        "Wall time: 3.95 s\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Why aren't things speeding up as fast as I'd expect?\n",
      "\n",
      "### Amdahl's Law\n",
      "At first, going from 1 core to 4 cores seems like it should give a 4x improvement, but in practice we never fully achieve that efficiency.\n",
      "\n",
      "**Amdahl's Law** basically states that parallelizing a certain aspect of your project will only save you as much time as that part would have taken.  If your project takes 1 hour to run, and you parallelize a portion that only took 30 seconds of that hour, your code is still going to take ~1 hour to run.\n",
      "\n",
      "Parallelization also tends to add *overhead*.  If done right, this overhead will be worth the overall speedup.  But things will work best if you make sure parallel processing is actually appropriate for what you're doing.\n",
      "\n",
      "## Examples of when to stay serial\n",
      "- when I have lots of small steps which **all depend on each other**\n",
      "- when I'm doing something **small + simple** which runs ~instantly (will the speed up be worth the extra time it takes to program?  Is the main source of slowness simply due to the overhead of python trying to read in my file, rather than actually running it?)\n",
      "- when I'm doing something **memory heavy** (<code>APLpy/Montage</code> eats up all my memory; if I try to process 4 images all at once, I'll need 4x the memory)\n",
      "- complicated Input/Output (read/write) operations\n",
      "\n",
      "# Further Reading\n",
      "Hat tip to http://chriskiehl.com/article/parallelism-in-one-line/, for a blog post that helped me get started with this.\n",
      "\n",
      "In C/C++/Fortran you can apply a similar parallel programming model called <code>OpenMP</code>.  Things work a little differently, but it's a good starting place for injecting easy parallelizations.  It requires *shared memory* though; things get more complicated when you want multiple computers to work together, each with their own memory.\n",
      "\n",
      "For applying similar concepts in C, I've liked this overview: http://gribblelab.org/CBootcamp/A2_Parallel_Programming_in_C.html. It's reasonably concise, while covering a lot of big topics, and giving a nubmer of simple working examples."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Most up-to-date version can be found at: https://github.com/egentry/AstroComputingSeminar_Parallel)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}